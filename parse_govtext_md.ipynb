{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# from llama_index import download_loader\n",
    "# MarkdownReader = download_loader(\"MarkdownReader\")\n",
    "# loader = MarkdownReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fp_to_tups = {}\n",
    "# for dp in doc_paths:\n",
    "#     fp_to_tups[dp] = loader.parse_tups(filepath=Path(dp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "doc_paths = glob('/home/watsonchua/work/search_engine/docs/govtext/raw_text/*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "fp_to_text = {}\n",
    "for dp in doc_paths:\n",
    "    with open(dp, 'r') as f:\n",
    "        data = f.read()\n",
    "    text = ''.join(BeautifulSoup(data).findAll(string=True))\n",
    "    text = re.sub(r\"---\\nsidebar_position: \\d\\n---\\n\\n#\\s\", '', text)\n",
    "    text = re.sub(r\"import.*;\", '', text)\n",
    "    # Merge hyphenated words\n",
    "    text = re.sub(r\"(\\w+)-\\n(\\w+)\", r\"\\1\\2\", text)\n",
    "    # # Fix newlines in the middle of sentences\n",
    "    # text = re.sub(r\"(?<!\\n\\s)\\n(?!\\s\\n)\", \" \", text.strip())\n",
    "    # Remove multiple newlines\n",
    "    text = re.sub(r\"\\n\\s*\\n\", \"\\n\\n\", text)\n",
    "    fp_to_text[dp] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/home/watsonchua/work/search_engine/docs/govtext/raw_text/datasets.txt': 'Datasets\\n\\nGovText is designed to be dataset-centric (i.e. the same dataset can be used for multiple analyses). Thus, you will be required to upload your dataset before proceeding to create an analysis.\\n\\nYou will find the dataset management page by clicking on the **Datasets** button in the navigation bar.\\n\\n### DATASETS OVERVIEW\\nOn the Datasets page, you can do the following:\\n\\n* Upload your datasets\\n* Update the metadata of an existing dataset, including dataset name, data classification and sensitivity\\n* View an overview of your datasets: total size of your raw datasets stored on GovText, size of individual datasets, and number of predictions done on a particular dataset\\n* Search for your datasets by name\\n* Delete your datasets\\n* Download your datasets\\n* Navigate to a particular dataset by clicking on a row displayed in the table\\n\\n> Overview of your datasets\\n> \\n![Dataset1.JPG](/img/Dataset1.JPG) \\n\\n### UPLOAD DATASET\\nClicking on the **Upload** button on the Datasets page or the home page will bring you to the dataset uploading page. \\n\\nThe data must be in an **excel (.xlsx / .xls)** or **CSV (.csv)** file and be in the **first worksheet** of the file.\\n\\nThe column that you wish to analyse must be named as “**text**”. Do format your data such that each row in the worksheet represents one document (an article, email, feedback etc.)\\n\\nDo note that each dataset file should be **less than 20MB**, and **should not exceed 10,000 documents**. For dataset files used for summarisation, only the **first 50 documents** will be processed and summarised.\\n\\nYou can refer to the picture below or download our sample datasets under [**Resources**](../resources/sample-datasets) for more details.\\n\\n![Dataset2.JPG](/img/Dataset2.JPG)\\n\\n### DELETE DATASET\\nA dataset can only be deleted when it is not used by any prediction. \\n\\nTo delete a dataset that is currently used for a prediction, please delete the corresponding prediction before deleting the dataset. You can find the list of predictions using a particular dataset from the individual dataset page.\\n\\n### INDIVIDUAL DATASET PAGE\\nOn the individual dataset page, you will be able to see the list of predictions that used the selected dataset, and preview its contents.\\n\\nYou can delete the predictions directly from this page if you wish to.\\n\\n> Individual dataset page\\n>\\n![Dataset3.JPG](/img/Dataset3.JPG) \\n',\n",
       " '/home/watsonchua/work/search_engine/docs/govtext/raw_text/stopwords.txt': 'Stopwords\\nStopwords are frequently used terms that do not provide additional meaning or context to a text. While GovText uses a default list of stopwords, users may choose to include their own domain-specific stopwords in their analysis. \\n\\n### CREATE STOPWORD COLLECTIONS\\nClick on the **Stopwords** button in the navigation bar to manage your stopword collections.\\n\\nRefer to the steps below to create your custom stopword collection:\\n\\n1. Click on the **+** button at the bottom of the screen\\n\\n2. Enter a name for your stopword collection\\n\\n3. Add some words to the collection (press **enter** key to add a word)\\n\\n4. Save the collection by clicking the **Save** button.\\n\\nThe animation below demonstrates this process.\\n\\n![CreateStopwords](/img/Stopwords_create.gif)\\n\\nInstead of keying in each word individually, you can also copy a list of stopwords from a document, such as notepad or excel, and paste the list into the stopwords collection. The list of stopwords inserted in this manner will be automatically separated by spaces and new line characters.\\n\\nBelow animation demostrates how to do it with the short cut.\\n\\n![CreateStopwordsShortCut](/img/stopwords_shortcut.gif)\\n\\n### EDIT OR DELETE STOPWORD COLLECTIONS\\n\\nClick the pen or the bin icon to edit or delete a stopword collection.\\n\\nIn the edit mode, you can change the stopword collection name, and add or remove stopwords.\\n\\n![EditStopwords](/img/Stopwords_edit.png)\\n',\n",
       " '/home/watsonchua/work/search_engine/docs/govtext/raw_text/FAQ.txt': 'FAQ\\n\\n## TOPIC MODELLING\\n### MODEL RELATED QUESTIONS\\n#### 1. Which are the Topic Modelling algorithms used by GovText? Why did you use them? \\n\\nGovText provides two options for Topic Modelling using the following algorithms: \\n* Latent Dirichlet Allocation (LDA)\\n* Correlated Topic Model (CTM)\\n\\nWe chose Latent Dirichlet Allocation (LDA) because it is the most commonly used Topic Modelling technique across various domains. It is a statistical, unsupervised machine learning model for discovering abstract topics which occur in a collection of documents. However, its limitation is the inability to model topic correlation.\\n\\nTherefore, we also added the Correlated Topic Model (CTM) algorithm so that users who want to see the correlation between topic models can do so. As compared to LDA, CTM uses a more flexible distribution for the topic proportions which allows for covariance structure. Even though it can give a more realistic model of the latent topic structure, it is much slower as compared to LDA.\\n\\n#### 2. What is the difference between the Topic Similarity and Topic Correlation scores? \\n\\nCorrelated Topic Modeling (CTM)\\nLatent Dirichlet Allocation (LDA)\\n\\nMeasure\\nTopic Correlation\\nTopic Similarity\\n\\nDistribution used\\nLogistic normal distribution\\nDirichlet distribution\\n\\nWhat this means\\nThe CTM model factors in the covariances between the different topics, since it uses a more flexible distribution for the topic proportions.\\nThe LDA model is not able to use the correlation among words across the corpus to generate more distinct topics like the CTM model.However, the CTM model requires a much longer run time, which may be too long for some users. On the other hand, it may be useful for some users to have a measure of how similar topics are in the LDA model. For example, they only want to look at topics with very distinct words and ignore/merge topics which have high word overlaps.Hence, GovText tries to estimate how similar the topics are in the LDA model after the model has been trained. This is done using a measure of how independent the words are between topics as a substitute for the correlation measure that CTM has.\\n\\n#### 3. Does GovText use Bag-of-Words or Term Frequency - Inverse Document Frequency (TF-IDF) for the term weights?\\nGovText uses the Bag-of-Words technique for Topic Modelling, as per the original algorithm. \\n\\nIn the introduction of this LDA paper, it states that TF-IDF provided “a relatively small amount of reduction in description length and reveals little in the way of inter- or intra- document statistical structure”. Hence, while TF-IDF can be used, it does not provide a significant advantage over the Bag-of-Words model. \\n\\n#### 4. How does the number of trials affect the results? \\nThe number of trials determines the number of models we train to find the most optimal models (see next question on how the models are evaluated).\\nIn each of these trials, we vary the following hyperparameters:\\n* Alpha (a higher alpha would mean that documents are made up of more topics)\\n* Beta (a higher beta would mean that topics are made up of most of the words in the corpus)\\n* Number of topics\\n\\n#### 5. How are the top 3 models selected? \\nAfter the trial models have been trained, we select the best models based on the coherence score, which has been shown to have the strongest correlation with human ratings of topic models.\\n\\nInstead of simply selecting the models with the maximum coherence scores, we used the formula ** abs|coherence score – 0.6|** to favour models which have coherence scores falling within the range of 0.4 to 0.8.\\n\\nThis is because a model with a coherence score lower than 0.4 is likely to have broad, general topics, while one with coherence score higher than 0.8 is likely to have topics which are too specific. It is difficult for users to interpret from the topic models what their dataset is about in both scenarios.\\n\\n#### 6. Why do some words appear in multiple word clouds? \\nTopics have to be interpreted using the collection of dominant keywords as a whole. \\n\\nFor example, if topic modelling was performed on Singapore news articles between January to July 2020, the following topics could appear:\\n\\nTopic\\nDominant Keywords\\nPossible interpretation\\n\\nTopic 1\\ncovid, government, job, support, budget\\nThis topic could be related to Budget 2020, which included the various government support schemes / pay-outs (Resilience, Solidarity and Fortitude Budgets). These schemes were meant to help Singaporeans tide over the covid-19 pandemic.\\n\\nTopic 2\\nelection, government, vote, party, covid\\nThis topic could be pertaining to the 2020 General Elections, of which precautions were taken to prevent the spread of covid-19.\\n\\nTopic 3\\ncovid, travel, government, border_control, quarantine\\nThis topic is likely referring to the travel restrictions implemented in wake of the coronavirus outbreak, and the subsequent discussions on travel air bubbles/reopening of borders.\\n\\nIn each of these topics, the terms covid and government were present in the top terms. However, the topics are still quite distinct.\\n\\n### PREPROCESSING QUESTIONS\\n#### 1. Can GovText automatically extract only the content from emails for analysis? \\nThe current version of GovText does not do any specific preprocessing for emails. This means that, given an email or an email thread, the whole email, together with the headers, closing phrases and confidentiality clauses will be included for analysis.\\n\\nWhile some of the default preprocessing steps may be helpful (removal of stopwords and dropping of tokens that look like email addresses), the automatic extraction of the content from the email is not currently supported.\\n\\n#### 2. How does GovText handle spelling mistakes and SG specific terms / abbreviations (MOH, otw etc.)? \\nGovText does not use a fixed vocabulary list. Therefore, words outside the English vocabulary (including Singlish words), and spelling mistakes are still treated as valid words for the Topic Models. In fact, if these words are important to a topic, they will appear in the topics and users will see them in the visualizations.\\n\\n#### 3. Does GovText use lemmatization or stemming for word normalization?\\nGovText uses lemmatization for word normalization, instead of stemming.\\n\\nThe main reason behind this is to ensure that the (root) words making up the topics are valid English words, so that users can easily interpret them.\\n\\nLemmatization is part of the default preprocessing steps for topic modelling. \\n\\nOnly English words will be lemmatized because GovText uses an English lemmatizer. Spelling mistakes will not be lemmatized. For example, the word “happiness” will be reduced to happy, but “hapy” will remain the same.\\n\\n#### 4. What are the pre-processing steps performed by GovText under Topic Modelling?\\nThe default pre-processing steps performed before topic modelling include the following:\\n* Sentence segmentation\\n* Part-of-speech (POS) tagging and tokenization\\n* Removal of stopwords\\n* Lemmatization\\n* Formation of n-grams\\n\\n#### 5. Are numbers dropped?\\nNumbers in both numerical (e.g. 1, 2, 3, 4, 5) and word (e.g. one, two, three, four, five) forms are dropped.\\n\\n#### 6. How does GovText handle spaces and punctuations?\\nSpaces and punctuations are removed as part of the default preprocessing steps on GovText. \\n\\n#### 7. How did you create the default stopwords list? \\nThe default stopwords on GovText is built on Spacy’s stopword list, made up of words in the English language which usually does not add additional information to the sentence.\\n\\nWe expanded this list by adding Singlish stopwords like lah, leh, hor etc. The full list is shown to users in the stopwords page\\n\\n#### 8. Does GovText include N-grams and Part-of-speech (POS) tagging? Will users be allowed to opt-out or customize these steps?\\nN-grams (bigrams and trigrams) and POS-tagging are part of the default preprocessing steps for Topic Modelling.\\n\\nUsers can see the n-grams in the output if they are important keywords in a topic. In addition, after POS-tagging is done, only adjectives, adverbs, nouns, proper nouns and verbs are used as input into the topic model.\\n\\nUsers do not have the option to exclude or alter these steps. \\n\\n## SUMMARIZATION\\n#### 1. What’s the abstractive summarisation model used by GovText?\\nGovText uses a Bidirectional and Auto Regressive Transformers (BART) model to do  abstractive summarisation. More information can be found at: https://ai.facebook.com/research/publications/bart-denoising-sequence-to-sequence-pre-training-for-natural-language-generation-translation-and-comprehension/ \\n\\n#### 2. How does GovText overcome the maximum token count limit set by the transformers-based abstractive summarisation model?\\nFor documents with lengths greater than the model limits, extractive summarisation is first done to reduce the lengths of the original documents by selecting only the most important sentences. Abstractive summarisation is then done on this extractive-summarised document. \\n\\n#### 3. What’s the maximum document length that could be summarised by GovText?\\nThere isn’t an explicit word limit for summarisation and the team has tested GovText able to process documents up to 50k words. \\n\\nPlease note that EXCEL file limits the total number of characters that a cell can contain to be 32,767 characters. However, if you know how to create a CSV file using a text editor, you can put in texts with much longer lengths (remember to save it in .csv format and upload it to GovText).\\n\\nHere is an example of how to do so https://help.smallbusiness.yahoo.net/s/article/SLN18690 but you will need to take care of line breaks and escape characters like “ in your document.\\n',\n",
       " '/home/watsonchua/work/search_engine/docs/govtext/raw_text/summarisation.txt': 'Summarisation\\n\\n## CONCEPT\\nGovText offers two summarisation options:\\n\\n1. **Normal**: using abstractive summarisation, the main points of a document are consolidated and paraphrased into a short paragraph which reads like a human written one  \\n2. **Quick**: using extractive summarisation, the most important sentences of a document are \"lifted\" and highlighted\\n\\nDue to the complexity involved in performing an abstractive summarisation (normal summary), it takes up more computing resources and time. Therefore, users need to enter the maximum length (number of words) of the summary they want, and only one summary which is shorter or equal to this length will be returned.  \\n\\nExtractive summarisation (quick summary) is very much faster than abstractive summarisation. When this option is activated, summaries of the following lengths will be returned for each document: \\n\\n1. Short (around 15% of original document length) \\n2. Medium (around 30% of original document length)\\n3. Long (around 45% of original document length)\\n\\nThe abstractive summarisation uses models pre-trained on summaries of news articles. Therefore, abstractive summarisation works best on similar articles. \\n\\n## SUBMIT AN ANALYSIS\\nClick on the **Predictions** button in the navigation bar, then select the **Summarisation** card.\\n\\nOn the Summarisation submission page:\\n\\n1. Enter a name for your analysis\\n2. Select a dataset from the existing dataset list \\n3. Change the configuration based on your needs\\n4. Click **Submit**\\n\\nIf the submission is successful, a message will appear to inform you of this.\\n\\nThe animation below demonstrates this process. \\n\\n![Summarisation_Config](/img/Summarisation1_Config.gif)\\n\\nThe maximum number of predictions in the **Created** or **In Progress** statuses is capped at 3 per user. That means that until 1 of the predictions is completed, you will not be allowed to submit any more predictions. \\n\\nWhen submitting a prediction, you will be informed of the number of predictions that are still being processed.\\n![CountInProgress](/img/TopicModelling_Submit2.JPG)\\n\\n### Select Dataset\\nOn the Summarisation submission page, you can find the full list of datasets that you have already uploaded. Select the dataset that you will be using for this analysis. \\n\\nYou can do a search using the dataset name.\\n\\n![Summarisation_DataFilter](/img/Summarisation2_DataFilter.gif)\\n\\nDo note that **only the first 50 documents in the Excel or CSV file will be processed**. Any documents after the 51st row in the spreadsheet will be discarded for summarisation. \\n\\nIf there are multiple documents in the Excel or CSV file (1 document per row in the file), each document will be summarised individually. \\n\\nIf you need to upload a new dataset, click on the **Upload New Dataset** button or the **Dataset** button in the navigation bar, to reach the  Dataset Upload page. The steps to upload a dataset can be found in the [Datasets](datasets) section. \\n\\nAfter successfully uploading your new dataset, you will need to return to the Summarisation submission page.\\n\\n### Summarisation Options\\nAs mentioned above, GovText offers two types of summarisation: \\n\\n1. By default (Quick Summary not checked), abstractive summarisation will be performed. This will return paraphrased summaries of the documents\\' main points but the time taken is longer. For this option, you will need to select the maximum summary length.\\n\\n    Do note that the summaries returned might not be close to the selected maximum summary length (but they will definitely not be more than this length). This is because the model score the words in the summary and decide on the optimum length which provides the most coherent one. From our experiments, the model produces the most coherent summaries with lengths around 200 words.\\n\\n2. If you select the Quick Summary option, key sentences from the documents will be highlighted using extractive summarisation. There is no need to select the maximum summary length for this option.\\n\\n![Summarisation_Config](/img/Summarisation4_Config.JPG)\\n\\n## CHECKING PROCESSING STATUS\\n\\nClick on the **Predictions** button on the navigation bar. \\n\\nUnder the List of Predictions table, you will see the processing status of all your submitted predictions. \\n\\nTo view the results of a completed prediction, click on the corresponding row. \\n\\n## VIEWING THE SUMMARY RESULTS\\n\\n### Normal (Abstractive) Summary\\nFor normal summaries, the main points are paraphrased and the summaries and presented as short paragraphs in the **Summary** panel.\\n\\nIf there are multiple documents in your dataset, use the arrows at the bottom of the page to switch between documents.\\n![Summarisation_Result_Abstractive](/img/Summarisation5_Results_Abs.JPG)\\n\\n### Quick (Extractive) Summary\\nIf the Quick Summary option is selected, the summaries will be in point forms, and the corresponding sentences in the original document will be highlighted.\\n\\nThree versions of the summaries will be shown - short, medium, and long. Click on the summary length buttons above the summary panel to switch between the versions.  \\n\\n![Summarisation_Result_Extractive](/img/Summarisation6_Results_Ext.JPG)\\n\\n### Other Utilities\\nThe **Download all results** icon is for downloading the full set of results.\\n\\nThe **Create new prediction** button is a shortcut to create a new prediction with the exact same settings as the current prediction.\\n\\n![Summarisation_Result_buttons](/img/Summarisation7_2buttons.gif)\\n\\n## DOWNLOAD ALL RESULTS\\nClick the **Download all results** button above the Original Document panel. \\n\\nThe summaries of all documents in the analysed dataset will be downloaded as a zip file. Please uncompress the file to view them.\\n\\nThe unzipped Excel file for the Normal (Abstractive) Summary results has 3 columns:\\n\\n* Column A: Document ID\\n* Column B: Original Document\\n* Column C: Summary\\n\\n![Summarisation_Result_DownloadAbstractive](/img/Summarisation8_DownloadAbs.JPG)\\n\\nThe unzipped Excel file for the Quick (Extractive) Summary results has 5 columns:\\n\\n* Column A: Document ID\\n* Column B: Original Document\\n* Column C: Short Summary\\n* Column D: Medium Summary\\n* Column E: Long Summary\\n\\n![Summarisation_Result_DownloadExtractive](/img/Summarisation9_DownloadExt.JPG)',\n",
       " '/home/watsonchua/work/search_engine/docs/govtext/raw_text/predictions.txt': 'Predictions\\n\\nTo create or manage your predictions, click on the **Predictions** button on the navigation bar. \\n\\nTo view the results of a prediction, click on the respective row in the table. \\n\\nTo create a new prediction, select the type of prediction you are interested in. \\n\\nYou can find more details on interpreting Topic Models here.\\n\\n![PredictionList.JPG](/img/PredictionList2.JPG)\\n',\n",
       " '/home/watsonchua/work/search_engine/docs/govtext/raw_text/navigation.txt': 'Navigation\\n\\n### HOME PAGE\\n\\nAfter you log in to GovText, you will be redirected to the home page. This page provides you with an overview of your recent activities, including:\\n\\n* The processing status of your most recent analysis \\n* Your storage utilisation\\n* Quick access to your last 6 analyses\\n\\n![WelcomePage.jpg](/img/WelcomePage.jpg)\\n\\nFrom the home page, you will be able to go to the **Datasets**, **Predictions** and **Stopwords** pages through the navigation bar. The navigation bar can be collapsed by clicking the folding icon next to the GovText logo.\\n\\nGovText is designed to be dataset-centric (i.e. the same dataset can be used for multiple analyses). Thus, you will be required to upload your dataset before proceeding to create an analysis. \\n\\n### DATASETS\\n\\nA dataset refers to the list of documents, feedback or other types of textual information that you need to analyse. The **Datasets** button in the navigation bar will bring you the page where you can upload and manage your datasets stored on GovText. Do note that we have imposed a **500MB storage limitation** for each user’s raw data, so please manage your datasets to keep within the limit.\\n\\n### PREDICTIONS\\n\\nA prediction refers to the results of an analysis. The **Predictions** button in the navigation bar will lead you to the page where you can choose your type of analysis (e.g. topic modelling or summarisation), and manage your past submitted analyses.\\n\\n### STOPWORDS\\n\\nStopwords are words that are not useful, or may negatively impact the analysis. Most of these stopwords will be automatically removed from your data during the pre-processing stage. However, in the event where domain-specific stopwords are required, you have the option of creating custom stopword lists under the **Stopwords** button in the navigation bar. You will be able to select which custom list to use when creating your analysis.\\n',\n",
       " '/home/watsonchua/work/search_engine/docs/govtext/raw_text/accessing-govtext.txt': \"Accessing GovText\\n\\n### SITE ADDRESS\\n\\nGovText is accessible from both the Internet and Intranet via https://www.govtext.gov.sg on a Google Chrome web browser.\\n\\n### ACCOUNT REGISTRATION\\n\\nTo register your account, click on the **Sign Up** button at the home page to start the registration process.\\n\\nPlease provide your name, email address and password. Do note that your email address must be a **Public Officer’s work email address** \\\\(e.g. those ending with .gov.sg\\\\).\\n\\nA valid password must contain at least 12 characters, and be a combination of:\\n\\n* Upper and lower case letters\\n* Digits \\\\(0-9\\\\)\\n* Special characters \\\\(@, !, etc.\\\\)\\n\\n![](/img/Doc_Access_CreateAccount.JPG)\\n\\nUpon hitting **Create Account**, a verification email will be sent to your registered email address. You can find a sample email below.\\n\\nOnce you have successfully verified your email address, you can proceed to log in and use GovText!\\n\\nIf you don't find the email in your Inbox, try checking your Spam mail box.\\n\\n![](/img/Doc_Access_CreateAccount3.JPG)\\n\\n### FORGOT PASSWORD\\n\\nIf you forgot your password, click the **Forgot password?** link to reset it.\\n\\n### ACCESS FROM INTRANET\\n\\nTo access GovText from your SOE laptop, go to [**https://www.govtext.gov.sg**](https://www.google.com/url?q=https%3A%2F%2Fwww.govtext.gov.sg&sa=D&sntz=1&usg=AFQjCNFmUQ09hqG2ukKuQllzPjWQNmnPaw) on a Google Chrome web browser.\\n\\nIf you are unable to access the site, it is likely that your agency has not whitelisted GovText yet. Please send us an email at [govtext@tech.gov.sg](mailto:govtext@tech.gov.sg) or [han_jing@tech.gov.sg](mailto:han_jing@tech.gov.sg) to find out more information regarding Intranet access to GovText, and how to proceed with your agency firewall application if it has not been done.\\n\\n### Data Classification and Sensitivity \\n\\nGovText resides in the Government Commercial Cloud \\\\(GCC\\\\), which **supports up to Restricted and Sensitive\\\\(Normal\\\\) data**. If you are accessing GovText from an Internet device, please be aware that classified data should not be transferred out of your SOE laptop, or processed over the Internet.\\n\",\n",
       " '/home/watsonchua/work/search_engine/docs/govtext/raw_text/topic-modelling.txt': 'Topic Modelling\\n\\n## CONCEPT\\n\\nTopic modelling is a statistical, unsupervised machine learning model for discovering abstract topics which occur in a collection of documents. This is done by determining the probability of each word belonging to each topic, and the proportion of each topic in each document. In other words, each word could belong to multiple topics, and as the document is formed by multiple words, a document could cover multiple topics too. \\n\\n## SUBMIT AN ANALYSIS\\nClick on the **Predictions** button in the navigation bar, then select the **Topic Modelling** card.\\n\\nOn the Topic Modelling submission page:\\n\\n1. Enter a name for your analysis\\n2. Select a dataset from the existing dataset list \\n3. Select the options based on your needs\\n4. Select a stopword collection if required\\n5. Click **Submit**\\n\\nYou will be informed if the submission is successful!\\n\\nThe animation below demonstrates the process. \\n\\n![Topic_Modelling_Submit1](/img/TopicModelling_Submit1.gif)\\n\\nThe maximum number of predictions in the **Created** or **In Progress** statuses is capped at 3 per user. That means that until 1 of the predictions is completed, you will not be allowed to submit any more predictions. \\n\\nWhen submitting a prediction, you will be informed of the number of predictions that are still being processed.\\n\\n![Topic_Modelling_Submit2](/img/TopicModelling_Submit2.JPG)\\n\\n### Select Dataset\\nOn the Topic Modelling submission page, you can find the full list of datasets that you have already uploaded. Select the dataset that you will be using for this analysis. \\n\\nYou can do a search using the dataset name to shorten the list.\\n\\n![Topic_Modelling_Submit3](/img/TopicModelling_Submit3.gif)\\n\\nIf you need to upload a new dataset, click on the **Upload New Dataset** button or the **Dataset** button in the navigation bar, to reach the  Dataset Upload page. The steps to upload a dataset can be found in the [**Datasets**](datasets) section. \\n\\nAfter successfully uploading your new dataset, you will need to return to Topic Modelling submission page.\\n\\n### Topic Modelling Configurations\\nThere are two configurable options for Topic Modelling: **Infer Relationship between Topics** and **Number of Trials**.\\n\\nTurning on the **Infer Relationship between Topics** option will activate the model which can infer correlations between topics. However, this will take a much longer processing time. Thus, for quick processing, this option is not recommended.\\n\\nThe **Number of Trials** option determines the number of models GovText will train to find more optimal models. The larger the number of trials, the more likely we can find more optimal models. However, it will also require a longer processing time. \\n\\n![Topic_Modelling_Submit4](/img/TopicModelling_Submit4.JPG)\\n\\nWithout the inferring relationship option, the number of trials can be an **integer between 3 and 100**. For a first try, we recommend a value between 10 to 20. \\n\\nWith the inferring relationship option, the number of trials can be an **integer between 3 and 20**. For a first try, we recommend a value between 5 to 10. \\n\\n### Select a Stopword Collection\\nStopwords are frequently used terms that do not provide additional meaning or context to a text. While GovText uses a default list of stopwords, users may choose to include their own domain-specific stopwords in their analysis. \\n\\nTo include your custom stopword collection in the analysis, please select it from the table. \\n\\nIf you have not created your custom stopword collection yet, refer to the following steps to do so on this page: \\n\\n1. Click on the **+** button at the bottom of the screen\\n2. Enter a name for your stopword collection\\n3. Add some words to the collection (press **enter** key to add a word)\\n4. Save the collection by clicking the **Save** button.\\n5. Select the collection before submitting the analysis\\n\\nThe animation below demonstrates this process. \\n\\nYou can also copy and paste your list of stopwords into the collection instead of keying them in individually. You can find the tips [here](stopwords).\\n\\n![Topic_Modelling_Submit5](/img/TopicModelling_Submit5.gif)\\n\\n## CHECKING STATUS & VIEWING RESULTS\\nClick on the **Predictions** button on the navigation bar. \\n\\nUnder the List of Predictions table, you will see the processing status of all your submitted predictions. \\n\\nTo view the results of a completed prediction, click on the corresponding row. \\n\\n## INTERPRETING THE RESULTS\\nGovText provides users with the **top 3 topic models**, largely based on the average coherence scores of the topics in a model. This score represents the degree of semantic similarity between the top scoring words in the topics.\\n\\n![Topic_Modelling_Results1](/img/TopicModelling_Results1_3models.JPG)\\n\\nIn each model, GovText provides three different perspectives of the results:\\n\\n1. The results overview\\n2. The topic page\\n3. The document page\\n\\nThrough the visualizations, you will be able to understand the topic model from both a high-level perspective and a low-level, detailed view.\\n\\n![Topic_Modelling_Results2](/img/TopicModelling_results2_3levelview30.gif)\\n\\n### Result Overview\\n#### _Coherence Score Plot_\\nThe coherence score of a topic represents the **degree of semantic similarity between its top scoring words**. You will be able to see the exact coherence score of a topic by hovering over its data point.\\n\\nThis diagram is downloadable via the download button on the top right corner. \\n\\n![Topic_Modelling_Results3](/img/TopicModelling_Results3_CoherentScore.gif)        |  ![Topic_Modelling_Results4](/img/TopicModelling_Results4_NetworkDiagram.gif)\\n:-------------------------:|:-------------------------:\\nCoherence Score |  Network Graph\\n\\n#### _Network Graph_\\nIf you have selected the option to infer relationships between topics, the links connecting the nodes will represent the degree of **correlation** between the 2 topics. If this option is not selected, the links would represent the degree of **similarity** between topics.  \\n\\nIn addition, the size of the nodes represents the size of the topics.\\n\\nWhen hovering the mouse above a node, the top five words of the topic will be displayed, so that you can get a quick sense of what the topic is about. \\n\\nYou can zoom in and out of the network graph by scrolling the wheel on your mouse within the diagram. You can also drag the graph using your mouse.\\n\\nYou can download the diagram as an image by clicking the download button at the top right corner.\\n\\n#### _Word Cloud_\\nEach topic in the results overview is represented as a word cloud. It is formed by the top 50 words with the highest word probability within the topic, and the size of the words represent their relative importance. \\n\\nYou can **search for a topic** by either typing a word of interest into the search bar (followed by enter key), or clicking a word on a word cloud. The search function supports partial word and multiple word searches, and will only keep the topics with matches found from their top 50 words. \\n\\nYou can download a word cloud as an image by clicking the download button at the top right corner.\\n\\n![Topic_Modelling_Results5](/img/TopicModelling_Results5_wordcloudsearch.gif)\\n\\n#### _Other Utilities_\\nThe **Expand word clouds** icon can be used to hide the coherence score and topic similarity/correlation diagrams. This will keep only the word cloud diagrams. \\n\\nClicking on the expand word clouds button again will show the hidden diagrams. \\n\\n![Topic_Modelling_Results6](/img/TopicModelling_Results6_3buttons.gif)\\n\\nThe **Download all results** icon is for downloading the full set of results, which is explained in detail at the end of this page.\\n\\nThe **Create new prediction** button is a shortcut to create a new prediction with the exact same settings as the current prediction.\\n\\n### Topic View\\nClick on a word cloud in the results overview page to navigate to the topic view page. \\n\\n#### _Top Words in Topic by Word Probability_ \\nThe diagram on the left displays the words in the selected topic, and its corresponding word probability value. This chart is downloadable as an image by clicking the download button at top right corner. \\n\\n**Word probability** is the probability of the word belonging to a topic. Each unique word in the dataset is assigned a set of probabilities of it belonging to each topic. For example, in a model with 4 topics,  a word is assigned a set of 4 probabilities. Each of the 4 values represents how likely the word belongs to each topic. Thus, it is possible for a word to appear in multiple word clouds. \\n\\n#### _Ranking of Documents by Topic Constitution_ \\nOn the right, you will see the full list of documents ranked by their **topic constitution scores** for the selected topic. \\n\\nEach document can be represented as a distribution of topics in which the document contains. \\n\\nFor example, in a model with 3 topics, a document could be made up of 60% topic 1, 30% topic 2 and 10% topic 3  (adds up to 100%). In this case, when topic 1 is selected, the topic constitution score displayed will be 0.6. Thus, changing the topic selected will change the ranking of the documents in the dataset. \\n\\nYou can reselect a topic by:\\n\\n* Clicking on the **Change Topics** button \\n* Going back to the results overview page, and select another word cloud\\n\\n![Topic_Modelling_Results7](/img/TopicModelling_Results7_breadcrumb1.JPG)\\n\\n### Document View\\nClick on a document in the topic page to navigate to the document view. \\n\\nThe Document view will show you how the topics are distributed inside the selected document. The words most relevant to the selected topic will be highlighted in the original document. You can choose to highlight the words relevant to other topics by clicking on the topic in the bar chart.\\n\\nYou can download the bar chart by clicking the download button at the top right corner.\\n\\n![Topic_Modelling_Results8](/img/TopicModelling_Results8_DocumentView.gif)\\n\\n## DOWNLOAD ALL RESULTS\\nIn the results overview page, the download button next to the search bar will allow you to download the full results of a selected model. For example, in screenshot below, clicking on the download button will download the full results for model 3. If you want to download the results for the other models, you need to navigate to other tabs and download the results there.\\n\\n![Topic_Modelling_Results9](/img/TopicModelling_Results9_DownloadAll.JPG)\\n\\nThe results will be downloaded as a zip file. Please uncompress the file.\\n\\nIn the Excel file, there are 4 tabs: \\n\\n* Topic Constitution\\n* Top Words\\n* Topic Similarity (or Topic Correlation)\\n* Topic Details\\n\\nIn the **Topic Constitution** tab, you will see the following:\\n\\n* Column A: document ID\\n* Column B: original text of the document\\n* Column C: text after preprocessing the original text\\n* Column D onwards: topic constitution scores by topic \\n\\nFor each document, the topic constitution scores correspond to the values seen in the documents list (in the topic view). \\n\\nIn the **Top Words** tab, you will see the following:\\n\\n* Column A: topic number\\n* Column B: rank of the word in the corresponding topic\\n* Column C: the processed word\\n* Column D: word probability (%) of the word in the topic \\n\\nThe word probabilities correspond to the values displayed in the _Top Words in Topic by Word Probability_ chart (in the topic view).\\n\\n![Topic_Modelling_Results10](/img/TopicModelling_Results10_downloadexcel1.png)\\n\\nIn the **Topic Similarity** tab (or **Topic Correlation** tab), you will find the similarity (or correlation) matrix. \\n\\nThe more positive the score is, the more similar/correlated the topics are. \\n\\nIn the **Topic Details** tab, you will find the coherence score of each topic and the size of the topic.\\n\\n![Topic_Modelling_Results11](/img/TopicModelling_results11_downloadexcel2.JPG)        |  ![Topic_Modelling_Results12](/img/TopicModelling_results12_downloadexcel3.JPG)\\n:-------------------------:|:-------------------------:\\nTopic Similarity Tab |  Topic Details Tab\\n',\n",
       " '/home/watsonchua/work/search_engine/docs/govtext/raw_text/team.txt': 'GovText is the NLP team in the Artificial Intelligence Platforms team headed by Director Alvina Goh. \\nIt is part of the Data Science and Artificial Intelligence Division (DSAID) of the Government Technology Agency of Singapore (GovTech).\\n\\nThe product team members are:\\n- Amelia (Data Scientist)\\n- Charlton (Software Engineer)\\n- Han Jing (Product Manager)\\n- Hung Siang (Software Engineer)\\n- Li Lu (Data Scientist)\\n- Ryan (DevOps Engineer)\\n- Watson (Data Scientist)\\n- Weiguang (Software Engineer)\\n- Sulaiman (Software Engineer)\\n- Shangru (Software Engineer)'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_to_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import tiktoken\n",
    "from ftfy import fix_text\n",
    "import os\n",
    "enc = tiktoken.encoding_for_model(\"gpt-3.5-turbo-0301\")\n",
    "\n",
    "def text_to_docs(fp_to_text, max_chunk_length=400):\n",
    "    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(encoding_name='cl100k_base',\n",
    "            chunk_size=max_chunk_length,                                                         \n",
    "            separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \",\", \" \", \"\"],\n",
    "            chunk_overlap=0,\n",
    "        )\n",
    "\n",
    "    counter = 1\n",
    "    doc_chunks = []\n",
    "\n",
    "    for filename, text in fp_to_text.items():\n",
    "        filename_truncated = filename[:-4].split(os.path.sep)[-1]\n",
    "        # for tup in text:\n",
    "        #     tup_text = '\\n'.join([t for t in tup if t is not None])\n",
    "        cc = fix_text(text)\n",
    "        cc_length = len(enc.encode(cc))\n",
    "        if cc_length == 0:\n",
    "            continue\n",
    "        if cc_length > max_chunk_length:\n",
    "            splits = text_splitter.split_text(cc)\n",
    "        else:\n",
    "            splits = [cc]\n",
    "\n",
    "        # clause_no = cc.split('\\n\\n')[0]        \n",
    "\n",
    "        for split_no, s in enumerate(splits):\n",
    "            source_key = 'C' + \"{:05d}\".format(counter)\n",
    "            split_length = len(enc.encode(s))\n",
    "            doc = Document(page_content=s, metadata={\"filename\": filename_truncated, \"length\": split_length, \"clause_no\": \"\", \"split_no\": str(split_no), \"source\": source_key})\n",
    "            # Display: filename.strip() + '--' +  clause_no.strip() + '--' + str(split_no)\n",
    "\n",
    "            doc_chunks.append(doc)\n",
    "            counter += 1\n",
    "    return doc_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_chunks = text_to_docs(fp_to_text, max_chunk_length=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Datasets\\n\\nGovText is designed to be dataset-centric (i.e. the same dataset can be used for multiple analyses). Thus, you will be required to upload your dataset before proceeding to create an analysis.\\n\\nYou will find the dataset management page by clicking on the **Datasets** button in the navigation bar.\\n\\n### DATASETS OVERVIEW\\nOn the Datasets page, you can do the following:\\n\\n* Upload your datasets\\n* Update the metadata of an existing dataset, including dataset name, data classification and sensitivity\\n* View an overview of your datasets: total size of your raw datasets stored on GovText, size of individual datasets, and number of predictions done on a particular dataset\\n* Search for your datasets by name\\n* Delete your datasets\\n* Download your datasets\\n* Navigate to a particular dataset by clicking on a row displayed in the table\\n\\n> Overview of your datasets\\n> \\n![Dataset1.JPG](/img/Dataset1.JPG) \\n\\n### UPLOAD DATASET\\nClicking on the **Upload** button on the Datasets page or the home page will bring you to the dataset uploading page. \\n\\nThe data must be in an **excel (.xlsx / .xls)** or **CSV (.csv)** file and be in the **first worksheet** of the file.\\n\\nThe column that you wish to analyse must be named as \"**text**\". Do format your data such that each row in the worksheet represents one document (an article, email, feedback etc.)\\n\\nDo note that each dataset file should be **less than 20MB**, and **should not exceed 10,000 documents**. For dataset files used for summarisation, only the **first 50 documents** will be processed and summarised.\\n\\nYou can refer to the picture below or download our sample datasets under [**Resources**](../resources/sample-datasets) for more details.\\n\\n![Dataset2.JPG](/img/Dataset2.JPG)', metadata={'filename': 'datasets', 'length': 387, 'clause_no': '', 'split_no': '0', 'source': 'C00001'}),\n",
       " Document(page_content='### DELETE DATASET\\nA dataset can only be deleted when it is not used by any prediction. \\n\\nTo delete a dataset that is currently used for a prediction, please delete the corresponding prediction before deleting the dataset. You can find the list of predictions using a particular dataset from the individual dataset page.\\n\\n### INDIVIDUAL DATASET PAGE\\nOn the individual dataset page, you will be able to see the list of predictions that used the selected dataset, and preview its contents.\\n\\nYou can delete the predictions directly from this page if you wish to.\\n\\n> Individual dataset page\\n>\\n![Dataset3.JPG](/img/Dataset3.JPG)', metadata={'filename': 'datasets', 'length': 128, 'clause_no': '', 'split_no': '1', 'source': 'C00002'}),\n",
       " Document(page_content='Stopwords\\nStopwords are frequently used terms that do not provide additional meaning or context to a text. While GovText uses a default list of stopwords, users may choose to include their own domain-specific stopwords in their analysis. \\n\\n### CREATE STOPWORD COLLECTIONS\\nClick on the **Stopwords** button in the navigation bar to manage your stopword collections.\\n\\nRefer to the steps below to create your custom stopword collection:\\n\\n1. Click on the **+** button at the bottom of the screen\\n\\n2. Enter a name for your stopword collection\\n\\n3. Add some words to the collection (press **enter** key to add a word)\\n\\n4. Save the collection by clicking the **Save** button.\\n\\nThe animation below demonstrates this process.\\n\\n![CreateStopwords](/img/Stopwords_create.gif)\\n\\nInstead of keying in each word individually, you can also copy a list of stopwords from a document, such as notepad or excel, and paste the list into the stopwords collection. The list of stopwords inserted in this manner will be automatically separated by spaces and new line characters.\\n\\nBelow animation demostrates how to do it with the short cut.\\n\\n![CreateStopwordsShortCut](/img/stopwords_shortcut.gif)\\n\\n### EDIT OR DELETE STOPWORD COLLECTIONS\\n\\nClick the pen or the bin icon to edit or delete a stopword collection.\\n\\nIn the edit mode, you can change the stopword collection name, and add or remove stopwords.\\n\\n![EditStopwords](/img/Stopwords_edit.png)\\n', metadata={'filename': 'stopwords', 'length': 308, 'clause_no': '', 'split_no': '0', 'source': 'C00003'}),\n",
       " Document(page_content='FAQ\\n\\n\\n\\n\\n\\n\\n\\n\\n## TOPIC MODELLING\\n### MODEL RELATED QUESTIONS\\n#### 1. Which are the Topic Modelling algorithms used by GovText? Why did you use them? \\n\\n\\nGovText provides two options for Topic Modelling using the following algorithms: \\n* Latent Dirichlet Allocation (LDA)\\n* Correlated Topic Model (CTM)\\n\\nWe chose Latent Dirichlet Allocation (LDA) because it is the most commonly used Topic Modelling technique across various domains. It is a statistical, unsupervised machine learning model for discovering abstract topics which occur in a collection of documents. However, its limitation is the inability to model topic correlation.\\n\\nTherefore, we also added the Correlated Topic Model (CTM) algorithm so that users who want to see the correlation between topic models can do so. As compared to LDA, CTM uses a more flexible distribution for the topic proportions which allows for covariance structure. Even though it can give a more realistic model of the latent topic structure, it is much slower as compared to LDA.\\n\\n#### 2. What is the difference between the Topic Similarity and Topic Correlation scores? \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCorrelated Topic Modeling (CTM)\\nLatent Dirichlet Allocation (LDA)\\n\\n\\nMeasure\\nTopic Correlation\\nTopic Similarity\\n\\n\\nDistribution used\\nLogistic normal distribution\\nDirichlet distribution', metadata={'filename': 'FAQ', 'length': 275, 'clause_no': '', 'split_no': '0', 'source': 'C00004'}),\n",
       " Document(page_content='What this means\\nThe CTM model factors in the covariances between the different topics, since it uses a more flexible distribution for the topic proportions.\\nThe LDA model is not able to use the correlation among words across the corpus to generate more distinct topics like the CTM model.However, the CTM model requires a much longer run time, which may be too long for some users. On the other hand, it may be useful for some users to have a measure of how similar topics are in the LDA model. For example, they only want to look at topics with very distinct words and ignore/merge topics which have high word overlaps.Hence, GovText tries to estimate how similar the topics are in the LDA model after the model has been trained. This is done using a measure of how independent the words are between topics as a substitute for the correlation measure that CTM has.\\n\\n\\n\\n\\n\\n\\n#### 3. Does GovText use Bag-of-Words or Term Frequency - Inverse Document Frequency (TF-IDF) for the term weights?\\nGovText uses the Bag-of-Words technique for Topic Modelling, as per the original algorithm. \\n\\nIn the introduction of this LDA paper, it states that TF-IDF provided \"a relatively small amount of reduction in description length and reveals little in the way of inter- or intra- document statistical structure\". Hence, while TF-IDF can be used, it does not provide a significant advantage over the Bag-of-Words model.', metadata={'filename': 'FAQ', 'length': 301, 'clause_no': '', 'split_no': '1', 'source': 'C00005'}),\n",
       " Document(page_content='#### 4. How does the number of trials affect the results? \\nThe number of trials determines the number of models we train to find the most optimal models (see next question on how the models are evaluated).\\nIn each of these trials, we vary the following hyperparameters:\\n* Alpha (a higher alpha would mean that documents are made up of more topics)\\n* Beta (a higher beta would mean that topics are made up of most of the words in the corpus)\\n* Number of topics\\n\\n#### 5. How are the top 3 models selected? \\nAfter the trial models have been trained, we select the best models based on the coherence score, which has been shown to have the strongest correlation with human ratings of topic models.\\n\\nInstead of simply selecting the models with the maximum coherence scores, we used the formula ** abs|coherence score – 0.6|** to favour models which have coherence scores falling within the range of 0.4 to 0.8.\\n\\nThis is because a model with a coherence score lower than 0.4 is likely to have broad, general topics, while one with coherence score higher than 0.8 is likely to have topics which are too specific. It is difficult for users to interpret from the topic models what their dataset is about in both scenarios.\\n\\n#### 6. Why do some words appear in multiple word clouds? \\nTopics have to be interpreted using the collection of dominant keywords as a whole. \\n\\nFor example, if topic modelling was performed on Singapore news articles between January to July 2020, the following topics could appear:\\n\\n\\n\\nTopic\\nDominant Keywords\\nPossible interpretation', metadata={'filename': 'FAQ', 'length': 330, 'clause_no': '', 'split_no': '2', 'source': 'C00006'}),\n",
       " Document(page_content='Topic 1\\ncovid, government, job, support, budget\\nThis topic could be related to Budget 2020, which included the various government support schemes / pay-outs (Resilience, Solidarity and Fortitude Budgets). These schemes were meant to help Singaporeans tide over the covid-19 pandemic.\\n\\n\\nTopic 2\\nelection, government, vote, party, covid\\nThis topic could be pertaining to the 2020 General Elections, of which precautions were taken to prevent the spread of covid-19.\\n\\n\\nTopic 3\\ncovid, travel, government, border_control, quarantine\\nThis topic is likely referring to the travel restrictions implemented in wake of the coronavirus outbreak, and the subsequent discussions on travel air bubbles/reopening of borders.\\n\\n\\n\\n\\n\\nIn each of these topics, the terms covid and government were present in the top terms. However, the topics are still quite distinct.\\n\\n### PREPROCESSING QUESTIONS\\n#### 1. Can GovText automatically extract only the content from emails for analysis? \\nThe current version of GovText does not do any specific preprocessing for emails. This means that, given an email or an email thread, the whole email, together with the headers, closing phrases and confidentiality clauses will be included for analysis.\\n\\nWhile some of the default preprocessing steps may be helpful (removal of stopwords and dropping of tokens that look like email addresses), the automatic extraction of the content from the email is not currently supported.\\n\\n#### 2. How does GovText handle spelling mistakes and SG specific terms / abbreviations (MOH, otw etc.)? \\nGovText does not use a fixed vocabulary list. Therefore, words outside the English vocabulary (including Singlish words), and spelling mistakes are still treated as valid words for the Topic Models. In fact, if these words are important to a topic, they will appear in the topics and users will see them in the visualizations.', metadata={'filename': 'FAQ', 'length': 383, 'clause_no': '', 'split_no': '3', 'source': 'C00007'}),\n",
       " Document(page_content='#### 3. Does GovText use lemmatization or stemming for word normalization?\\nGovText uses lemmatization for word normalization, instead of stemming.\\n\\nThe main reason behind this is to ensure that the (root) words making up the topics are valid English words, so that users can easily interpret them.\\n\\nLemmatization is part of the default preprocessing steps for topic modelling. \\n\\nOnly English words will be lemmatized because GovText uses an English lemmatizer. Spelling mistakes will not be lemmatized. For example, the word \"happiness\" will be reduced to happy, but \"hapy\" will remain the same.\\n\\n#### 4. What are the pre-processing steps performed by GovText under Topic Modelling?\\nThe default pre-processing steps performed before topic modelling include the following:\\n* Sentence segmentation\\n* Part-of-speech (POS) tagging and tokenization\\n* Removal of stopwords\\n* Lemmatization\\n* Formation of n-grams\\n\\n#### 5. Are numbers dropped?\\nNumbers in both numerical (e.g. 1, 2, 3, 4, 5) and word (e.g. one, two, three, four, five) forms are dropped.\\n\\n#### 6. How does GovText handle spaces and punctuations?\\nSpaces and punctuations are removed as part of the default preprocessing steps on GovText. \\n\\n#### 7. How did you create the default stopwords list? \\nThe default stopwords on GovText is built on Spacy\\'s stopword list, made up of words in the English language which usually does not add additional information to the sentence.\\n\\nWe expanded this list by adding Singlish stopwords like lah, leh, hor etc. The full list is shown to users in the stopwords page', metadata={'filename': 'FAQ', 'length': 363, 'clause_no': '', 'split_no': '4', 'source': 'C00008'}),\n",
       " Document(page_content=\"#### 8. Does GovText include N-grams and Part-of-speech (POS) tagging? Will users be allowed to opt-out or customize these steps?\\nN-grams (bigrams and trigrams) and POS-tagging are part of the default preprocessing steps for Topic Modelling.\\n\\nUsers can see the n-grams in the output if they are important keywords in a topic. In addition, after POS-tagging is done, only adjectives, adverbs, nouns, proper nouns and verbs are used as input into the topic model.\\n\\nUsers do not have the option to exclude or alter these steps. \\n\\n## SUMMARIZATION\\n#### 1. What's the abstractive summarisation model used by GovText?\\nGovText uses a Bidirectional and Auto Regressive Transformers (BART) model to do  abstractive summarisation. More information can be found at: https://ai.facebook.com/research/publications/bart-denoising-sequence-to-sequence-pre-training-for-natural-language-generation-translation-and-comprehension/ \\n\\n#### 2. How does GovText overcome the maximum token count limit set by the transformers-based abstractive summarisation model?\\nFor documents with lengths greater than the model limits, extractive summarisation is first done to reduce the lengths of the original documents by selecting only the most important sentences. Abstractive summarisation is then done on this extractive-summarised document.\", metadata={'filename': 'FAQ', 'length': 289, 'clause_no': '', 'split_no': '5', 'source': 'C00009'}),\n",
       " Document(page_content='#### 3. What\\'s the maximum document length that could be summarised by GovText?\\nThere isn\\'t an explicit word limit for summarisation and the team has tested GovText able to process documents up to 50k words. \\n \\nPlease note that EXCEL file limits the total number of characters that a cell can contain to be 32,767 characters. However, if you know how to create a CSV file using a text editor, you can put in texts with much longer lengths (remember to save it in .csv format and upload it to GovText).\\n \\nHere is an example of how to do so https://help.smallbusiness.yahoo.net/s/article/SLN18690 but you will need to take care of line breaks and escape characters like \" in your document.', metadata={'filename': 'FAQ', 'length': 157, 'clause_no': '', 'split_no': '6', 'source': 'C00010'}),\n",
       " Document(page_content='Summarisation\\n\\n## CONCEPT\\nGovText offers two summarisation options:\\n\\n1. **Normal**: using abstractive summarisation, the main points of a document are consolidated and paraphrased into a short paragraph which reads like a human written one  \\n2. **Quick**: using extractive summarisation, the most important sentences of a document are \"lifted\" and highlighted\\n\\nDue to the complexity involved in performing an abstractive summarisation (normal summary), it takes up more computing resources and time. Therefore, users need to enter the maximum length (number of words) of the summary they want, and only one summary which is shorter or equal to this length will be returned.  \\n\\nExtractive summarisation (quick summary) is very much faster than abstractive summarisation. When this option is activated, summaries of the following lengths will be returned for each document: \\n\\n1. Short (around 15% of original document length) \\n2. Medium (around 30% of original document length)\\n3. Long (around 45% of original document length)\\n\\nThe abstractive summarisation uses models pre-trained on summaries of news articles. Therefore, abstractive summarisation works best on similar articles. \\n\\n## SUBMIT AN ANALYSIS\\nClick on the **Predictions** button in the navigation bar, then select the **Summarisation** card.\\n\\nOn the Summarisation submission page:\\n\\n1. Enter a name for your analysis\\n2. Select a dataset from the existing dataset list \\n3. Change the configuration based on your needs\\n4. Click **Submit**\\n\\nIf the submission is successful, a message will appear to inform you of this.\\n\\nThe animation below demonstrates this process. \\n\\n![Summarisation_Config](/img/Summarisation1_Config.gif)', metadata={'filename': 'summarisation', 'length': 363, 'clause_no': '', 'split_no': '0', 'source': 'C00011'}),\n",
       " Document(page_content=\"The maximum number of predictions in the **Created** or **In Progress** statuses is capped at 3 per user. That means that until 1 of the predictions is completed, you will not be allowed to submit any more predictions. \\n\\nWhen submitting a prediction, you will be informed of the number of predictions that are still being processed.\\n![CountInProgress](/img/TopicModelling_Submit2.JPG)\\n\\n### Select Dataset\\nOn the Summarisation submission page, you can find the full list of datasets that you have already uploaded. Select the dataset that you will be using for this analysis. \\n\\nYou can do a search using the dataset name.\\n\\n![Summarisation_DataFilter](/img/Summarisation2_DataFilter.gif)\\n\\nDo note that **only the first 50 documents in the Excel or CSV file will be processed**. Any documents after the 51st row in the spreadsheet will be discarded for summarisation. \\n\\n\\nIf there are multiple documents in the Excel or CSV file (1 document per row in the file), each document will be summarised individually. \\n\\nIf you need to upload a new dataset, click on the **Upload New Dataset** button or the **Dataset** button in the navigation bar, to reach the  Dataset Upload page. The steps to upload a dataset can be found in the [Datasets](datasets) section. \\n\\nAfter successfully uploading your new dataset, you will need to return to the Summarisation submission page.\\n\\n### Summarisation Options\\nAs mentioned above, GovText offers two types of summarisation: \\n\\n1. By default (Quick Summary not checked), abstractive summarisation will be performed. This will return paraphrased summaries of the documents' main points but the time taken is longer. For this option, you will need to select the maximum summary length.\", metadata={'filename': 'summarisation', 'length': 369, 'clause_no': '', 'split_no': '1', 'source': 'C00012'}),\n",
       " Document(page_content='Do note that the summaries returned might not be close to the selected maximum summary length (but they will definitely not be more than this length). This is because the model score the words in the summary and decide on the optimum length which provides the most coherent one. From our experiments, the model produces the most coherent summaries with lengths around 200 words.\\n\\n2. If you select the Quick Summary option, key sentences from the documents will be highlighted using extractive summarisation. There is no need to select the maximum summary length for this option.\\n\\n![Summarisation_Config](/img/Summarisation4_Config.JPG)\\n\\n\\n\\n## CHECKING PROCESSING STATUS\\n\\nClick on the **Predictions** button on the navigation bar. \\n\\nUnder the List of Predictions table, you will see the processing status of all your submitted predictions. \\n\\nTo view the results of a completed prediction, click on the corresponding row. \\n\\n## VIEWING THE SUMMARY RESULTS\\n\\n### Normal (Abstractive) Summary\\nFor normal summaries, the main points are paraphrased and the summaries and presented as short paragraphs in the **Summary** panel.\\n\\nIf there are multiple documents in your dataset, use the arrows at the bottom of the page to switch between documents.\\n![Summarisation_Result_Abstractive](/img/Summarisation5_Results_Abs.JPG)\\n\\n\\n### Quick (Extractive) Summary\\nIf the Quick Summary option is selected, the summaries will be in point forms, and the corresponding sentences in the original document will be highlighted.\\n\\nThree versions of the summaries will be shown - short, medium, and long. Click on the summary length buttons above the summary panel to switch between the versions.  \\n\\n![Summarisation_Result_Extractive](/img/Summarisation6_Results_Ext.JPG)\\n\\n\\n### Other Utilities\\nThe **Download all results** icon is for downloading the full set of results.', metadata={'filename': 'summarisation', 'length': 381, 'clause_no': '', 'split_no': '2', 'source': 'C00013'}),\n",
       " Document(page_content='The **Create new prediction** button is a shortcut to create a new prediction with the exact same settings as the current prediction.\\n\\n![Summarisation_Result_buttons](/img/Summarisation7_2buttons.gif)\\n\\n\\n## DOWNLOAD ALL RESULTS\\nClick the **Download all results** button above the Original Document panel. \\n\\nThe summaries of all documents in the analysed dataset will be downloaded as a zip file. Please uncompress the file to view them.\\n\\n\\n\\nThe unzipped Excel file for the Normal (Abstractive) Summary results has 3 columns:\\n\\n* Column A: Document ID\\n* Column B: Original Document\\n* Column C: Summary\\n\\n![Summarisation_Result_DownloadAbstractive](/img/Summarisation8_DownloadAbs.JPG)\\n\\nThe unzipped Excel file for the Quick (Extractive) Summary results has 5 columns:\\n\\n* Column A: Document ID\\n* Column B: Original Document\\n* Column C: Short Summary\\n* Column D: Medium Summary\\n* Column E: Long Summary\\n\\n![Summarisation_Result_DownloadExtractive](/img/Summarisation9_DownloadExt.JPG)', metadata={'filename': 'summarisation', 'length': 231, 'clause_no': '', 'split_no': '3', 'source': 'C00014'}),\n",
       " Document(page_content='Predictions\\n\\nTo create or manage your predictions, click on the **Predictions** button on the navigation bar. \\n\\nTo view the results of a prediction, click on the respective row in the table. \\n\\nTo create a new prediction, select the type of prediction you are interested in. \\n\\nYou can find more details on interpreting Topic Models here.\\n\\n![PredictionList.JPG](/img/PredictionList2.JPG)\\n', metadata={'filename': 'predictions', 'length': 84, 'clause_no': '', 'split_no': '0', 'source': 'C00015'}),\n",
       " Document(page_content=\"Navigation\\n\\n### HOME PAGE\\n\\nAfter you log in to GovText, you will be redirected to the home page. This page provides you with an overview of your recent activities, including:\\n\\n* The processing status of your most recent analysis \\n* Your storage utilisation\\n* Quick access to your last 6 analyses\\n\\n![WelcomePage.jpg](/img/WelcomePage.jpg)\\n\\nFrom the home page, you will be able to go to the **Datasets**, **Predictions** and **Stopwords** pages through the navigation bar. The navigation bar can be collapsed by clicking the folding icon next to the GovText logo.\\n\\nGovText is designed to be dataset-centric (i.e. the same dataset can be used for multiple analyses). Thus, you will be required to upload your dataset before proceeding to create an analysis. \\n\\n\\n### DATASETS\\n\\nA dataset refers to the list of documents, feedback or other types of textual information that you need to analyse. The **Datasets** button in the navigation bar will bring you the page where you can upload and manage your datasets stored on GovText. Do note that we have imposed a **500MB storage limitation** for each user's raw data, so please manage your datasets to keep within the limit.\\n\\n### PREDICTIONS\\n\\nA prediction refers to the results of an analysis. The **Predictions** button in the navigation bar will lead you to the page where you can choose your type of analysis (e.g. topic modelling or summarisation), and manage your past submitted analyses.\\n\\n### STOPWORDS\\n\\nStopwords are words that are not useful, or may negatively impact the analysis. Most of these stopwords will be automatically removed from your data during the pre-processing stage. However, in the event where domain-specific stopwords are required, you have the option of creating custom stopword lists under the **Stopwords** button in the navigation bar. You will be able to select which custom list to use when creating your analysis.\\n\", metadata={'filename': 'navigation', 'length': 395, 'clause_no': '', 'split_no': '0', 'source': 'C00016'}),\n",
       " Document(page_content=\"Accessing GovText\\n\\n### SITE ADDRESS\\n\\nGovText is accessible from both the Internet and Intranet via https://www.govtext.gov.sg on a Google Chrome web browser.\\n\\n\\n### ACCOUNT REGISTRATION\\n\\nTo register your account, click on the **Sign Up** button at the home page to start the registration process.\\n\\nPlease provide your name, email address and password. Do note that your email address must be a **Public Officer's work email address** \\\\(e.g. those ending with .gov.sg\\\\).\\n\\nA valid password must contain at least 12 characters, and be a combination of:\\n\\n* Upper and lower case letters\\n* Digits \\\\(0-9\\\\)\\n* Special characters \\\\(@, !, etc.\\\\)\\n\\n![](/img/Doc_Access_CreateAccount.JPG)\\n\\nUpon hitting **Create Account**, a verification email will be sent to your registered email address. You can find a sample email below.\\n\\nOnce you have successfully verified your email address, you can proceed to log in and use GovText!\\n\\nIf you don't find the email in your Inbox, try checking your Spam mail box.\\n\\n![](/img/Doc_Access_CreateAccount3.JPG)\\n\\n### FORGOT PASSWORD\\n\\nIf you forgot your password, click the **Forgot password?** link to reset it.\\n\\n\\n### ACCESS FROM INTRANET\\n\\nTo access GovText from your SOE laptop, go to [**https://www.govtext.gov.sg**](https://www.google.com/url?q=https%3A%2F%2Fwww.govtext.gov.sg&sa=D&sntz=1&usg=AFQjCNFmUQ09hqG2ukKuQllzPjWQNmnPaw) on a Google Chrome web browser.\", metadata={'filename': 'accessing-govtext', 'length': 357, 'clause_no': '', 'split_no': '0', 'source': 'C00017'}),\n",
       " Document(page_content='If you are unable to access the site, it is likely that your agency has not whitelisted GovText yet. Please send us an email at [govtext@tech.gov.sg](mailto:govtext@tech.gov.sg) or [han_jing@tech.gov.sg](mailto:han_jing@tech.gov.sg) to find out more information regarding Intranet access to GovText, and how to proceed with your agency firewall application if it has not been done.\\n\\n\\n### Data Classification and Sensitivity \\n\\nGovText resides in the Government Commercial Cloud \\\\(GCC\\\\), which **supports up to Restricted and Sensitive\\\\(Normal\\\\) data**. If you are accessing GovText from an Internet device, please be aware that classified data should not be transferred out of your SOE laptop, or processed over the Internet.', metadata={'filename': 'accessing-govtext', 'length': 165, 'clause_no': '', 'split_no': '1', 'source': 'C00018'}),\n",
       " Document(page_content='Topic Modelling\\n\\n## CONCEPT\\n\\nTopic modelling is a statistical, unsupervised machine learning model for discovering abstract topics which occur in a collection of documents. This is done by determining the probability of each word belonging to each topic, and the proportion of each topic in each document. In other words, each word could belong to multiple topics, and as the document is formed by multiple words, a document could cover multiple topics too. \\n\\n## SUBMIT AN ANALYSIS\\nClick on the **Predictions** button in the navigation bar, then select the **Topic Modelling** card.\\n\\nOn the Topic Modelling submission page:\\n\\n1. Enter a name for your analysis\\n2. Select a dataset from the existing dataset list \\n3. Select the options based on your needs\\n4. Select a stopword collection if required\\n5. Click **Submit**\\n\\nYou will be informed if the submission is successful!\\n\\nThe animation below demonstrates the process. \\n\\n![Topic_Modelling_Submit1](/img/TopicModelling_Submit1.gif)\\n\\n\\nThe maximum number of predictions in the **Created** or **In Progress** statuses is capped at 3 per user. That means that until 1 of the predictions is completed, you will not be allowed to submit any more predictions. \\n\\nWhen submitting a prediction, you will be informed of the number of predictions that are still being processed.\\n\\n![Topic_Modelling_Submit2](/img/TopicModelling_Submit2.JPG)\\n\\n### Select Dataset\\nOn the Topic Modelling submission page, you can find the full list of datasets that you have already uploaded. Select the dataset that you will be using for this analysis. \\n\\nYou can do a search using the dataset name to shorten the list.\\n\\n![Topic_Modelling_Submit3](/img/TopicModelling_Submit3.gif)', metadata={'filename': 'topic-modelling', 'length': 368, 'clause_no': '', 'split_no': '0', 'source': 'C00019'}),\n",
       " Document(page_content='If you need to upload a new dataset, click on the **Upload New Dataset** button or the **Dataset** button in the navigation bar, to reach the  Dataset Upload page. The steps to upload a dataset can be found in the [**Datasets**](datasets) section. \\n\\nAfter successfully uploading your new dataset, you will need to return to Topic Modelling submission page.\\n\\n### Topic Modelling Configurations\\nThere are two configurable options for Topic Modelling: **Infer Relationship between Topics** and **Number of Trials**.\\n\\nTurning on the **Infer Relationship between Topics** option will activate the model which can infer correlations between topics. However, this will take a much longer processing time. Thus, for quick processing, this option is not recommended.\\n\\nThe **Number of Trials** option determines the number of models GovText will train to find more optimal models. The larger the number of trials, the more likely we can find more optimal models. However, it will also require a longer processing time. \\n\\n![Topic_Modelling_Submit4](/img/TopicModelling_Submit4.JPG)\\n\\nWithout the inferring relationship option, the number of trials can be an **integer between 3 and 100**. For a first try, we recommend a value between 10 to 20. \\n\\nWith the inferring relationship option, the number of trials can be an **integer between 3 and 20**. For a first try, we recommend a value between 5 to 10. \\n\\n### Select a Stopword Collection\\nStopwords are frequently used terms that do not provide additional meaning or context to a text. While GovText uses a default list of stopwords, users may choose to include their own domain-specific stopwords in their analysis. \\n\\nTo include your custom stopword collection in the analysis, please select it from the table.', metadata={'filename': 'topic-modelling', 'length': 374, 'clause_no': '', 'split_no': '1', 'source': 'C00020'}),\n",
       " Document(page_content='If you have not created your custom stopword collection yet, refer to the following steps to do so on this page: \\n\\n\\n1. Click on the **+** button at the bottom of the screen\\n2. Enter a name for your stopword collection\\n3. Add some words to the collection (press **enter** key to add a word)\\n4. Save the collection by clicking the **Save** button.\\n5. Select the collection before submitting the analysis\\n\\nThe animation below demonstrates this process. \\n\\nYou can also copy and paste your list of stopwords into the collection instead of keying them in individually. You can find the tips [here](stopwords).\\n\\n![Topic_Modelling_Submit5](/img/TopicModelling_Submit5.gif)\\n\\n## CHECKING STATUS & VIEWING RESULTS\\nClick on the **Predictions** button on the navigation bar. \\n\\nUnder the List of Predictions table, you will see the processing status of all your submitted predictions. \\n\\nTo view the results of a completed prediction, click on the corresponding row. \\n\\n## INTERPRETING THE RESULTS\\nGovText provides users with the **top 3 topic models**, largely based on the average coherence scores of the topics in a model. This score represents the degree of semantic similarity between the top scoring words in the topics.\\n\\n![Topic_Modelling_Results1](/img/TopicModelling_Results1_3models.JPG)\\n\\nIn each model, GovText provides three different perspectives of the results:\\n\\n1. The results overview\\n2. The topic page\\n3. The document page\\n\\nThrough the visualizations, you will be able to understand the topic model from both a high-level perspective and a low-level, detailed view.\\n\\n![Topic_Modelling_Results2](/img/TopicModelling_results2_3levelview30.gif)', metadata={'filename': 'topic-modelling', 'length': 369, 'clause_no': '', 'split_no': '2', 'source': 'C00021'}),\n",
       " Document(page_content='### Result Overview\\n#### _Coherence Score Plot_\\nThe coherence score of a topic represents the **degree of semantic similarity between its top scoring words**. You will be able to see the exact coherence score of a topic by hovering over its data point.\\n\\nThis diagram is downloadable via the download button on the top right corner. \\n\\n![Topic_Modelling_Results3](/img/TopicModelling_Results3_CoherentScore.gif)        |  ![Topic_Modelling_Results4](/img/TopicModelling_Results4_NetworkDiagram.gif)\\n:-------------------------:|:-------------------------:\\nCoherence Score |  Network Graph\\n\\n\\n\\n#### _Network Graph_\\nIf you have selected the option to infer relationships between topics, the links connecting the nodes will represent the degree of **correlation** between the 2 topics. If this option is not selected, the links would represent the degree of **similarity** between topics.  \\n\\nIn addition, the size of the nodes represents the size of the topics.\\n\\nWhen hovering the mouse above a node, the top five words of the topic will be displayed, so that you can get a quick sense of what the topic is about. \\n\\nYou can zoom in and out of the network graph by scrolling the wheel on your mouse within the diagram. You can also drag the graph using your mouse.\\n\\nYou can download the diagram as an image by clicking the download button at the top right corner.\\n\\n\\n#### _Word Cloud_\\nEach topic in the results overview is represented as a word cloud. It is formed by the top 50 words with the highest word probability within the topic, and the size of the words represent their relative importance.', metadata={'filename': 'topic-modelling', 'length': 337, 'clause_no': '', 'split_no': '3', 'source': 'C00022'}),\n",
       " Document(page_content='You can **search for a topic** by either typing a word of interest into the search bar (followed by enter key), or clicking a word on a word cloud. The search function supports partial word and multiple word searches, and will only keep the topics with matches found from their top 50 words. \\n\\nYou can download a word cloud as an image by clicking the download button at the top right corner.\\n\\n![Topic_Modelling_Results5](/img/TopicModelling_Results5_wordcloudsearch.gif)\\n\\n#### _Other Utilities_\\nThe **Expand word clouds** icon can be used to hide the coherence score and topic similarity/correlation diagrams. This will keep only the word cloud diagrams. \\n\\nClicking on the expand word clouds button again will show the hidden diagrams. \\n\\n![Topic_Modelling_Results6](/img/TopicModelling_Results6_3buttons.gif)\\n\\nThe **Download all results** icon is for downloading the full set of results, which is explained in detail at the end of this page.\\n\\nThe **Create new prediction** button is a shortcut to create a new prediction with the exact same settings as the current prediction.\\n\\n### Topic View\\nClick on a word cloud in the results overview page to navigate to the topic view page. \\n\\n#### _Top Words in Topic by Word Probability_ \\nThe diagram on the left displays the words in the selected topic, and its corresponding word probability value. This chart is downloadable as an image by clicking the download button at top right corner.', metadata={'filename': 'topic-modelling', 'length': 305, 'clause_no': '', 'split_no': '4', 'source': 'C00023'}),\n",
       " Document(page_content='**Word probability** is the probability of the word belonging to a topic. Each unique word in the dataset is assigned a set of probabilities of it belonging to each topic. For example, in a model with 4 topics,  a word is assigned a set of 4 probabilities. Each of the 4 values represents how likely the word belongs to each topic. Thus, it is possible for a word to appear in multiple word clouds. \\n\\n#### _Ranking of Documents by Topic Constitution_ \\nOn the right, you will see the full list of documents ranked by their **topic constitution scores** for the selected topic. \\n\\nEach document can be represented as a distribution of topics in which the document contains. \\n\\nFor example, in a model with 3 topics, a document could be made up of 60% topic 1, 30% topic 2 and 10% topic 3  (adds up to 100%). In this case, when topic 1 is selected, the topic constitution score displayed will be 0.6. Thus, changing the topic selected will change the ranking of the documents in the dataset. \\n\\nYou can reselect a topic by:\\n\\n* Clicking on the **Change Topics** button \\n* Going back to the results overview page, and select another word cloud\\n\\n![Topic_Modelling_Results7](/img/TopicModelling_Results7_breadcrumb1.JPG)\\n\\n### Document View\\nClick on a document in the topic page to navigate to the document view. \\n\\nThe Document view will show you how the topics are distributed inside the selected document. The words most relevant to the selected topic will be highlighted in the original document. You can choose to highlight the words relevant to other topics by clicking on the topic in the bar chart.\\n\\nYou can download the bar chart by clicking the download button at the top right corner.', metadata={'filename': 'topic-modelling', 'length': 376, 'clause_no': '', 'split_no': '5', 'source': 'C00024'}),\n",
       " Document(page_content='![Topic_Modelling_Results8](/img/TopicModelling_Results8_DocumentView.gif)\\n\\n## DOWNLOAD ALL RESULTS\\nIn the results overview page, the download button next to the search bar will allow you to download the full results of a selected model. For example, in screenshot below, clicking on the download button will download the full results for model 3. If you want to download the results for the other models, you need to navigate to other tabs and download the results there.\\n\\n![Topic_Modelling_Results9](/img/TopicModelling_Results9_DownloadAll.JPG)\\n\\nThe results will be downloaded as a zip file. Please uncompress the file.\\n\\nIn the Excel file, there are 4 tabs: \\n\\n* Topic Constitution\\n* Top Words\\n* Topic Similarity (or Topic Correlation)\\n* Topic Details\\n\\nIn the **Topic Constitution** tab, you will see the following:\\n\\n* Column A: document ID\\n* Column B: original text of the document\\n* Column C: text after preprocessing the original text\\n* Column D onwards: topic constitution scores by topic \\n\\nFor each document, the topic constitution scores correspond to the values seen in the documents list (in the topic view). \\n\\nIn the **Top Words** tab, you will see the following:\\n\\n* Column A: topic number\\n* Column B: rank of the word in the corresponding topic\\n* Column C: the processed word\\n* Column D: word probability (%) of the word in the topic \\n\\nThe word probabilities correspond to the values displayed in the _Top Words in Topic by Word Probability_ chart (in the topic view).\\n\\n![Topic_Modelling_Results10](/img/TopicModelling_Results10_downloadexcel1.png)\\n\\nIn the **Topic Similarity** tab (or **Topic Correlation** tab), you will find the similarity (or correlation) matrix.', metadata={'filename': 'topic-modelling', 'length': 382, 'clause_no': '', 'split_no': '6', 'source': 'C00025'}),\n",
       " Document(page_content='The more positive the score is, the more similar/correlated the topics are. \\n\\nIn the **Topic Details** tab, you will find the coherence score of each topic and the size of the topic.\\n\\n![Topic_Modelling_Results11](/img/TopicModelling_results11_downloadexcel2.JPG)        |  ![Topic_Modelling_Results12](/img/TopicModelling_results12_downloadexcel3.JPG)\\n:-------------------------:|:-------------------------:\\nTopic Similarity Tab |  Topic Details Tab', metadata={'filename': 'topic-modelling', 'length': 105, 'clause_no': '', 'split_no': '7', 'source': 'C00026'}),\n",
       " Document(page_content='GovText is the NLP team in the Artificial Intelligence Platforms team headed by Director Alvina Goh. \\nIt is part of the Data Science and Artificial Intelligence Division (DSAID) of the Government Technology Agency of Singapore (GovTech).\\n\\nThe product team members are:\\n- Amelia (Data Scientist)\\n- Charlton (Software Engineer)\\n- Han Jing (Product Manager)\\n- Hung Siang (Software Engineer)\\n- Li Lu (Data Scientist)\\n- Ryan (DevOps Engineer)\\n- Watson (Data Scientist)\\n- Weiguang (Software Engineer)\\n- Sulaiman (Software Engineer)\\n- Shangru (Software Engineer)', metadata={'filename': 'team', 'length': 126, 'clause_no': '', 'split_no': '0', 'source': 'C00027'})]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_ai_embeddings import OpenAIEmbeddings\n",
    "import toml, openai\n",
    "secrets = toml.load('.streamlit/secrets.toml')\n",
    "\n",
    "openai_api_key = secrets['openai_api_key_azure']\n",
    "openai.api_key = openai_api_key\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"https://govtext-ds-experiment.openai.azure.com/\"\n",
    "openai.api_version = \"2022-12-01\"\n",
    "# azure_completion_engine = \"text-davinci-003-pretrained\"\n",
    "azure_completion_engine = \"gpt-35-turbo-0301-pretrained\"\n",
    "azure_embedding_engine = \"text-embedding-ada-002-pretrained\"\n",
    "\n",
    "oai_embedder = OpenAIEmbeddings(query_model_name=azure_embedding_engine, document_model_name=azure_embedding_engine, openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.faiss import FAISS\n",
    "db_clauses = FAISS.from_documents(doc_chunks, oai_embedder)\n",
    "db_clauses.save_local('./govtext_user_guide_docs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: govtext_user_guide_docs/index.pkl to s3://govtext-qa-index-db/govtext_user_guide_docs/index.pkl\n",
      "upload: govtext_user_guide_docs/index.faiss to s3://govtext-qa-index-db/govtext_user_guide_docs/index.faiss\n"
     ]
    }
   ],
   "source": [
    "!aws s3 sync ./govtext_user_guide_docs \"s3://govtext-qa-index-db/govtext_user_guide_docs\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
